{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subjectNumber', 'scenarioNumber', 'newAfterOld', 'scenarioType',\n",
       "       'displayType', 'sensorPlacementTime', 'ppvStartTime', 'ccStartTime',\n",
       "       'inSpO2TargetRangeDuration', 'inSpO2LooseTargetRangeDuration',\n",
       "       'inSpO2TargetRangeStartTime', 'aboveSpO2TargetRangeDuration',\n",
       "       'belowSpO2TargetRangeDuration', 'inFiO2TargetRangeDuration',\n",
       "       'inFiO2TargetRangeStartTime', 'aboveFiO2TargetRangeDuration',\n",
       "       'belowFiO2TargetRangeDuration', 'spO2SignedErrorIntegral',\n",
       "       'spO2UnsignedErrorIntegral', 'spO2SquaredErrorIntegral',\n",
       "       'fiO2LargeAdjustments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracing_df = statistics.load_tracing_features()\n",
    "tracing_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Type Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_pairing = statistics.build_pairing(tracing_df, 'scenarioType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against scenarioType:\n",
      "  0: easy vs. 1: hard\n",
      "  40 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "scenario_pairing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = 9.800; stdev diff = 37.349\n",
      "  Paired t-test:\n",
      "   ~|diff| > 0: p = 0.109\n",
      "    diff < 0: p = 0.945\n",
      "   *diff > 0: p = 0.055\n",
      "  Wilcoxon signed-rank test:\n",
      "   ~P(x > y) != 0.5: p = 0.110\n",
      "    P(x > y) < 0.5: p = 0.945\n",
      "   *P(x > y) > 0.5: p = 0.055\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = 54.200; stdev diff = 35.827\n",
      "  Paired t-test:\n",
      "  **|diff| > 0: p = 0.000\n",
      "    diff < 0: p = 1.000\n",
      "  **diff > 0: p = 0.000\n",
      "  Wilcoxon signed-rank test:\n",
      "  **P(x > y) != 0.5: p = 0.000\n",
      "    P(x > y) < 0.5: p = 1.000\n",
      "  **P(x > y) > 0.5: p = 0.000\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(scenario_pairing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Wilcoxon signed-rank and paired t-tests seem to behave generally the same way.\n",
    "* Participants seem to perform better on the easy scenario than the hard scenario, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Type Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pairing = statistics.build_pairing(tracing_df, 'displayType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against displayType:\n",
      "  0: minimal vs. 1: full\n",
      "  44 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "display_pairing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = -0.136; stdev diff = 34.405\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.979\n",
      "    diff < 0: p = 0.490\n",
      "    diff > 0: p = 0.510\n",
      "  Wilcoxon signed-rank test:\n",
      "    P(x > y) != 0.5: p = 0.844\n",
      "    P(x > y) < 0.5: p = 0.422\n",
      "    P(x > y) > 0.5: p = 0.578\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = 1.045; stdev diff = 38.446\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.859\n",
      "    diff < 0: p = 0.570\n",
      "    diff > 0: p = 0.430\n",
      "  Wilcoxon signed-rank test:\n",
      "    P(x > y) != 0.5: p = 0.769\n",
      "    P(x > y) < 0.5: p = 0.615\n",
      "    P(x > y) > 0.5: p = 0.385\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(display_pairing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Wilcoxon signed-rank and paired t-tests seem to behave generally the same way.\n",
    "* No outcomes show significant differences. This suggests that we need to split the groups by scenario difficulty, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Type Pairing, Split by Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_display_pairings = {\n",
    "    scenario: statistics.build_pairing(scenario_subset, 'displayType')\n",
    "    for (scenario, scenario_subset) in enumerate(scenario_pairing)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against displayType:\n",
      "  0: minimal vs. 1: full\n",
      "  20 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "scenario_display_pairings[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = -8.800; stdev diff = 35.504\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.293\n",
      "   ~diff < 0: p = 0.147\n",
      "    diff > 0: p = 0.853\n",
      "  Wilcoxon signed-rank test:\n",
      "   ~P(x > y) != 0.5: p = 0.151\n",
      "   *P(x > y) < 0.5: p = 0.075\n",
      "    P(x > y) > 0.5: p = 0.925\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = -5.000; stdev diff = 47.017\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.648\n",
      "    diff < 0: p = 0.324\n",
      "    diff > 0: p = 0.676\n",
      "  Wilcoxon signed-rank test:\n",
      "    P(x > y) != 0.5: p = 0.533\n",
      "    P(x > y) < 0.5: p = 0.266\n",
      "    P(x > y) > 0.5: p = 0.734\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(scenario_display_pairings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Wilcoxon signed-rank and paired t-tests seem to behave generally the same way.\n",
    "* No outcomes show significant differences. Thus, we can't conclude that the display improves performance during easy scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against displayType:\n",
      "  0: minimal vs. 1: full\n",
      "  20 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "scenario_display_pairings[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = 14.000; stdev diff = 27.691\n",
      "  Paired t-test:\n",
      "  **|diff| > 0: p = 0.040\n",
      "    diff < 0: p = 0.980\n",
      "  **diff > 0: p = 0.020\n",
      "  Wilcoxon signed-rank test:\n",
      "  **P(x > y) != 0.5: p = 0.044\n",
      "    P(x > y) < 0.5: p = 0.978\n",
      "  **P(x > y) > 0.5: p = 0.022\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = 11.400; stdev diff = 26.443\n",
      "  Paired t-test:\n",
      "   *|diff| > 0: p = 0.076\n",
      "    diff < 0: p = 0.962\n",
      "  **diff > 0: p = 0.038\n",
      "  Wilcoxon signed-rank test:\n",
      "   *P(x > y) != 0.5: p = 0.088\n",
      "    P(x > y) < 0.5: p = 0.956\n",
      "  **P(x > y) > 0.5: p = 0.044\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(scenario_display_pairings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* There is a lower time in the SpO2 strict target range with the full display. Same for the loose target range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "* The display doesn't seem to improve outcomes on the easy scenario.\n",
    "* The display seems to make outcomes worse on the hard scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Order Pairing, Split by Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_order_pairings = {\n",
    "    0: statistics.build_pairing(scenario_pairing[0], 'scenarioNumber', values=(1, 4), check_validity=False),\n",
    "    1: statistics.build_pairing(scenario_pairing[1], 'scenarioNumber', values=(2, 3), check_validity=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against scenarioNumber:\n",
      "  0: first vs. 1: second\n",
      "  20 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "scenario_order_pairings[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = -19.200; stdev diff = 31.135\n",
      "  Paired t-test:\n",
      "  **|diff| > 0: p = 0.015\n",
      "  **diff < 0: p = 0.007\n",
      "    diff > 0: p = 0.993\n",
      "  Wilcoxon signed-rank test:\n",
      "  **P(x > y) != 0.5: p = 0.021\n",
      "  **P(x > y) < 0.5: p = 0.010\n",
      "    P(x > y) > 0.5: p = 0.990\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = -21.600; stdev diff = 42.060\n",
      "  Paired t-test:\n",
      "  **|diff| > 0: p = 0.037\n",
      "  **diff < 0: p = 0.019\n",
      "    diff > 0: p = 0.981\n",
      "  Wilcoxon signed-rank test:\n",
      "  **P(x > y) != 0.5: p = 0.015\n",
      "  **P(x > y) < 0.5: p = 0.007\n",
      "    P(x > y) > 0.5: p = 0.993\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(scenario_order_pairings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Participants in scenario 1 take longer (compared to scenario 4) to place the sensor, start PPV, and reach the SpO2 target range.\n",
    "* Participants in scenario 4 spend more time (compared to scenario 1) in the SpO2 target range.\n",
    "* Participants in scenario 1 accumulate higher absolute and squared errors (compared to scenario 4).\n",
    "* These results all point to a learning effect between scenarios 1 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing against scenarioNumber:\n",
      "  0: first vs. 1: second\n",
      "  20 0 vs. 1 pairs.\n",
      "  Paired t-test alternative hypotheses:\n",
      "    Ha left-tailed (diff < 0): mean 0 - mean 1 < 0\n",
      "    Ha two-tailed (|diff| > 0): mean 0 - mean 1 != 0\n",
      "    Ha right-tailed (diff > 0): mean 0 - mean 1 > 0\n",
      "  Wilcoxon signed-rank alternative hypotheses:\n",
      "    Ha left-tailed (P(x > y) < 0.5)\n",
      "    Ha two-tailed (P(x > y) != 0.5)\n",
      "    Ha right-tailed (P(x > y) > 0.5)\n"
     ]
    }
   ],
   "source": [
    "scenario_order_pairings[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inSpO2TargetRangeDuration:\n",
      "  mean diff = 7.800; stdev diff = 30.033\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.272\n",
      "    diff < 0: p = 0.864\n",
      "   ~diff > 0: p = 0.136\n",
      "  Wilcoxon signed-rank test:\n",
      "    P(x > y) != 0.5: p = 0.293\n",
      "    P(x > y) < 0.5: p = 0.853\n",
      "   ~P(x > y) > 0.5: p = 0.147\n",
      "inSpO2LooseTargetRangeDuration:\n",
      "  mean diff = 4.600; stdev diff = 28.426\n",
      "  Paired t-test:\n",
      "    |diff| > 0: p = 0.489\n",
      "    diff < 0: p = 0.755\n",
      "    diff > 0: p = 0.245\n",
      "  Wilcoxon signed-rank test:\n",
      "    P(x > y) != 0.5: p = 0.453\n",
      "    P(x > y) < 0.5: p = 0.773\n",
      "    P(x > y) > 0.5: p = 0.227\n"
     ]
    }
   ],
   "source": [
    "statistics.test_tracing_outcomes(scenario_order_pairings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Participants in scenario 2 take longer (compared to scenario 3) to place the sensor and start CC. There is no significant difference for starting PPV or entering the SpO2 target range.\n",
    "* There are no significant differences for time in SpO2 and FiO2 target ranges between scenarios 2 and 3.\n",
    "* There are no significant differences for accumulated errors between scenarios 2 and 3. Caveat is that accumulated squared error might be higher in scenario 2 than 3.\n",
    "* These results do not suggest a learning effect between scenarios 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "* There seems to be a learning effect between scenarios 1 and 4, but not between scenarios 2 and 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
